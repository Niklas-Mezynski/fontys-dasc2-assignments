{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = load_mnist('data/', kind='train')\n",
    "X_test, y_test = load_mnist('data/', kind='t10k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_elapsed_time (start_time):\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(\"Elapsed time: %.2f seconds\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 81.83 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "measure_elapsed_time(start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.83 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: %.2f %%\" % (100 * accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 187), (10000, 187))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, use PCA to reduce the dataset's dimensionality (with an explained variance ratio of 95%).\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "X_train_reduced.shape, X_test_reduced.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 117.46 seconds\n",
      "Accuracy: 85.64 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf.fit(X_train_reduced, y_train)\n",
    "\n",
    "measure_elapsed_time(start_time)\n",
    "\n",
    "y_pred = rf.predict(X_test_reduced)\n",
    "\n",
    "print(\"Accuracy: %.2f %%\" % (100 * accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Against my expecations the training time doubled altough the dimenions of the training set have been reduced. This should not happen as the model needs to process less data and therefore should be faster.\n",
    "The accuracy on the other side went up by using Principal Component Analysis. This is because the model has less dimensions to process and therefore can focus on the important features. This leads to a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 19.62 seconds\n",
      "Accuracy: 84.12 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niklas/uni/semester7/dasc2/dasc2-assignments/dasc2_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax regression (using the X_train dataset) and time how long it takes, then evaluate the resulting model on the test set. Use LogisticRegression with multi_class set to \"multinomial\".\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "softmax_reg.fit(X_train, y_train)\n",
    "\n",
    "measure_elapsed_time(start_time)\n",
    "\n",
    "y_pred = softmax_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: %.2f %%\" % (100 * accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 7.01 seconds\n",
      "Accuracy: 84.25 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niklas/uni/semester7/dasc2/dasc2-assignments/dasc2_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Use softmax regression (with the reduced dataset) and time how long it takes. Was training much faster? By how much?\n",
    "\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "softmax_reg.fit(X_train_reduced, y_train)\n",
    "\n",
    "measure_elapsed_time(start_time)\n",
    "\n",
    "y_pred = softmax_reg.predict(X_test_reduced)\n",
    "\n",
    "print(\"Accuracy: %.2f %%\" % (100 * accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the accuracy stays almost the same (0.13% higher) altough the training time is much faster (2.8 times faster). This is because the model has less dimensions to process and therefore can focus on the important features. But although the training time is faster the accuracy is almost the same. This is because the model has less dimensions to process and therefore can focus on the important features. This prevents overfitting and therefore leads to a better accuracy.\n",
    "PCA is a good way to reduce the dimensions of the training set and therefore the training time. It also prevents overfitting and therefore leads to a better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Dimensionality reduction with t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12500, 784), (12500,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a random subset of 12,500 images (x_train_small and y_train_small)\n",
    "np.random.seed(42)\n",
    "\n",
    "m = 12500\n",
    "indices = np.random.permutation(60000)[:m]\n",
    "\n",
    "X_train_small = X_train[indices]\n",
    "y_train_small = y_train[indices]\n",
    "\n",
    "X_train_small.shape, y_train_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 32.28 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12500, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's use t-SNE to reduce dimensionality down to 2D. Hint use sklearn manifold library\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "X_train_small_tsne = tsne.fit_transform(X_train_small)\n",
    "\n",
    "measure_elapsed_time(start_time)\n",
    "\n",
    "X_train_small_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dasc2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
